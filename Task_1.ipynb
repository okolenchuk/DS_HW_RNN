{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTqeVbt84hWCPGal8ew08u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okolenchuk/DS_HW_RNN/blob/main/Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучите простую рекуррентную нейронную сеть (без GRU/LSTM, без внимания) решать задачу дешифровки шифра Цезаря:\n",
        "1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на N каждой буквы). Например если N=2, то буква A переходит в букву C. Можно поиграться с\n",
        "языком на выбор (немецкий, русский и т.д.)\n",
        "2. Создать архитектуру рекуррентной нейронной сети.\n",
        "3. Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза).\n",
        "4. Проверить качество модели.\n",
        "\n",
        "\n",
        "2 балла за правильно выполненное задание."
      ],
      "metadata": {
        "id": "hu5AdfZrYbWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import warnings\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "np.set_printoptions(threshold=1000)"
      ],
      "metadata": {
        "id": "o2HAvpCDcJPC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем файл с текстом из интернета"
      ],
      "metadata": {
        "id": "lHnxCK8gW8-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ku2kLBLUW3XF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cb9c22-286b-4564-9fc1-3e97b17a4966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-18 10:28:57--  https://tululu.org/txt.php?id=51554\n",
            "Resolving tululu.org (tululu.org)... 104.21.82.5, 172.67.167.88, 2606:4700:3034::6815:5205, ...\n",
            "Connecting to tululu.org (tululu.org)|104.21.82.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 667704 (652K) [text/plain]\n",
            "Saving to: ‘txt.php?id=51554.4’\n",
            "\n",
            "\rtxt.php?id=51554.4    0%[                    ]       0  --.-KB/s               \rtxt.php?id=51554.4  100%[===================>] 652.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-09-18 10:28:57 (27.1 MB/s) - ‘txt.php?id=51554.4’ saved [667704/667704]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://tululu.org/txt.php?id=51554"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/txt.php?id=51554'\n",
        "string_size = 60\n",
        "batch_size = 10\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.01"
      ],
      "metadata": {
        "id": "sG4a6DuppJ2s"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс для кодирования текста по правилам шифта Цезаря с заданным шагом, и раскодировки для проверки на незнакомом корпусе текста. Также создает словарь для кодировки при чтении файла."
      ],
      "metadata": {
        "id": "IY8jM_BTYAxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cesar(object):\n",
        "    def __init__(self, step):\n",
        "        self.step = step\n",
        "        self.alphabet = ''\n",
        "        self.len_alphabet = 0\n",
        "\n",
        "    def alphabet_from_file(self, file_path):\n",
        "        with open(file_path) as file:\n",
        "            while True:\n",
        "                text = file.read(string_size)\n",
        "                if not text:\n",
        "                    break\n",
        "                for ch in text:\n",
        "                    if ch not in self.alphabet:\n",
        "                        self.alphabet += ch\n",
        "        self.alphabet = re.sub(r'[^a-zA-Z.!? ]+', r'', ''.join(sorted(self.alphabet)))\n",
        "        self.len_alphabet = len(self.alphabet)\n",
        "\n",
        "    def encode(self, text):\n",
        "        res = ''\n",
        "        for c in text:\n",
        "            if c in self.alphabet:\n",
        "                res += self.alphabet[(self.alphabet.index(c) + self.step) % len(self.alphabet)]\n",
        "        return res\n",
        "\n",
        "    def decode(self, text):\n",
        "        res = ''\n",
        "        for c in text:\n",
        "            res += self.alphabet[(self.alphabet.index(c) - self.step% len(self.alphabet))]\n",
        "        return res\n",
        "\n",
        "coder = Cesar(2)\n",
        "coder.alphabet_from_file(file_path)\n",
        "alpha = coder.alphabet\n",
        "alpha"
      ],
      "metadata": {
        "id": "U71xz6-0X_gZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa8a8ec3-69db-4089-bbe2-4abefa8b8eed"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' !.?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переводим части текста в массив чисел по индексу буквы в словаре и генерируем тензоры для обучения"
      ],
      "metadata": {
        "id": "yEYYF6oiITb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_index(sentence):\n",
        "    return [alpha.find(y) for y in sentence]"
      ],
      "metadata": {
        "id": "40O72RQ5G4zq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tensor(file_path, step):\n",
        "    text_array = []\n",
        "    with open(file_path) as file:\n",
        "        while True:\n",
        "            text = file.read(step)\n",
        "            if not text:\n",
        "                break\n",
        "            text_array.append(re.sub(r'[^a-zA-Z.!? ]', r' ', text))\n",
        "    del text_array[-1]\n",
        "    y_train = torch.tensor([sent_to_index(lines) for lines in text_array[:len(text_array) // 5]])\n",
        "    x_train = torch.tensor([sent_to_index(coder.encode(lines)) for lines in text_array[:len(text_array) // 5]])\n",
        "\n",
        "    y_test = torch.tensor([sent_to_index(lines) for lines in text_array[len(text_array) // 5:]])\n",
        "    x_test = torch.tensor([sent_to_index(coder.encode(lines)) for lines in text_array[len(text_array) // 5:]])\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "qKUqXFMstiQe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = make_tensor(file_path, string_size)"
      ],
      "metadata": {
        "id": "qC_PKMetP4LZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс для датасетов для подачи в даталоадер."
      ],
      "metadata": {
        "id": "PgQtz-3dIu0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        self._len = len(x)\n",
        "        self.y = y\n",
        "        self.x = x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "uthtmZrubcxT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torch.utils.data.DataLoader(MyDataset(x_train, y_train), \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=True)\n",
        "test_ds = torch.utils.data.DataLoader(MyDataset(x_test, y_test), \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=True)"
      ],
      "metadata": {
        "id": "wHLltvFyRPbn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простая RNN модель"
      ],
      "metadata": {
        "id": "8vLFKQzoI1gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = torch.nn.Embedding(60, 32)\n",
        "        self.rnn = torch.nn.RNN(32, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128, len(alpha))\n",
        "\n",
        "    def forward(self, sentence, state=None):\n",
        "        x = self.embed(sentence)\n",
        "        out, hidden = self.rnn(x)\n",
        "        return self.linear(out)"
      ],
      "metadata": {
        "id": "vVbEqG9Ntuli"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализация модели, фукции потерь и оптимизатора"
      ],
      "metadata": {
        "id": "RhBARzJVJEWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel().to(DEVICE)\n",
        "loss = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "jZCqaNPykT7Q"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc, iter_num = .0, .0, .0\n",
        "    start_epoch_time = time.time()\n",
        "    model.train()\n",
        "    for x, y in train_ds:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.view(1, -1).squeeze().to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model.forward(x).view(-1, len(alpha))\n",
        "        l = loss(out, y)\n",
        "        train_loss += l.item()\n",
        "        batch_acc = (out.argmax(dim=1) == y)\n",
        "        train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        iter_num += 1\n",
        "    print(f\"Epoch: {epoch+1}, loss: {train_loss:.4f}, acc: \"\n",
        "        f\"{train_acc / iter_num:.4f}\",\n",
        "        end=\" | \")\n",
        "    test_loss, test_acc, iter_num = .0, .0, .0\n",
        "    model.eval()\n",
        "    for x, y in test_ds:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.view(1, -1).squeeze()\n",
        "        out = model.forward(x).view(-1, len(alpha)).to(DEVICE)\n",
        "        l = loss(out, y)\n",
        "        test_loss += l.item()\n",
        "        batch_acc = (out.argmax(dim=1) == y)\n",
        "        test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
        "        iter_num += 1\n",
        "    print(\n",
        "        f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
        "        f\"{time.time() - start_epoch_time:.2f} sec.\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt7V1NoTt6-L",
        "outputId": "1159ff3b-30a1-4b80-8192-d59fa3630e20"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, loss: 600.1979, acc: 0.5252 | test loss: 1598.0606, test acc: 0.6597 | 5.67 sec.\n",
            "Epoch: 2, loss: 305.5320, acc: 0.7456 | test loss: 927.3700, test acc: 0.8050 | 5.59 sec.\n",
            "Epoch: 3, loss: 187.6041, acc: 0.8619 | test loss: 603.3845, test acc: 0.9226 | 5.51 sec.\n",
            "Epoch: 4, loss: 126.7920, acc: 0.9359 | test loss: 426.7960, test acc: 0.9466 | 5.57 sec.\n",
            "Epoch: 5, loss: 92.3589, acc: 0.9543 | test loss: 322.7798, test acc: 0.9609 | 5.46 sec.\n",
            "Epoch: 6, loss: 71.5211, acc: 0.9664 | test loss: 258.0250, test acc: 0.9670 | 5.67 sec.\n",
            "Epoch: 7, loss: 58.2054, acc: 0.9695 | test loss: 215.4007, test acc: 0.9698 | 5.53 sec.\n",
            "Epoch: 8, loss: 49.2153, acc: 0.9724 | test loss: 185.8385, test acc: 0.9715 | 5.48 sec.\n",
            "Epoch: 9, loss: 42.8484, acc: 0.9735 | test loss: 164.4314, test acc: 0.9723 | 5.56 sec.\n",
            "Epoch: 10, loss: 38.1784, acc: 0.9753 | test loss: 148.3478, test acc: 0.9763 | 5.53 sec.\n",
            "Epoch: 11, loss: 34.6118, acc: 0.9785 | test loss: 135.8581, test acc: 0.9778 | 5.55 sec.\n",
            "Epoch: 12, loss: 31.8111, acc: 0.9792 | test loss: 125.8666, test acc: 0.9779 | 5.59 sec.\n",
            "Epoch: 13, loss: 29.5648, acc: 0.9792 | test loss: 117.6850, test acc: 0.9779 | 5.56 sec.\n",
            "Epoch: 14, loss: 27.6947, acc: 0.9796 | test loss: 110.8262, test acc: 0.9796 | 5.49 sec.\n",
            "Epoch: 15, loss: 26.1221, acc: 0.9810 | test loss: 104.9582, test acc: 0.9806 | 5.56 sec.\n",
            "Epoch: 16, loss: 24.7669, acc: 0.9811 | test loss: 99.8506, test acc: 0.9806 | 5.53 sec.\n",
            "Epoch: 17, loss: 23.5783, acc: 0.9811 | test loss: 95.3339, test acc: 0.9806 | 5.50 sec.\n",
            "Epoch: 18, loss: 22.5216, acc: 0.9816 | test loss: 91.2858, test acc: 0.9815 | 5.52 sec.\n",
            "Epoch: 19, loss: 21.5666, acc: 0.9824 | test loss: 87.6176, test acc: 0.9821 | 5.47 sec.\n",
            "Epoch: 20, loss: 20.7015, acc: 0.9830 | test loss: 84.2646, test acc: 0.9824 | 5.41 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ячейка для тестирования модели на любом тексте, в sentence можно внести любой текст на английском для проверки."
      ],
      "metadata": {
        "id": "O_okU-P2J8xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"Jupyter Notebook\n",
        "Jupyter notebook, formerly known as the IPython notebook, is a flexible tool that helps you create readable analyses, \n",
        "as you can keep code, images, comments, formulae and plots together.\"\"\"\n",
        "encrypted_sentence = coder.encode(sentence)\n",
        "encrypted_sentence_idx = sent_to_index(encrypted_sentence)\n",
        "result = model(torch.tensor([encrypted_sentence_idx]).to(DEVICE)).argmax(dim=2)\n",
        "deencrypted_sentence = \"\".join([alpha[i.item()] for i in result.flatten()])\n",
        "print(f'Encrypted sentence is : \\n{encrypted_sentence}')\n",
        "print(\"-\" * 20)\n",
        "print(f'Predicted sentence: \\n{deencrypted_sentence}')\n",
        "print(f'Decrypted sentence is : \\n{coder.decode(encrypted_sentence)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uQLpQj7uHzF",
        "outputId": "75b4fa1d-3b98-4d9d-ce42-c7b50de1c849"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encrypted sentence is : \n",
            "Lwr vgt.PqvgdqqmLwr vgt.pqvgdqqm.hqtogtn .mpqyp.cu.vjg.KR vjqp.pqvgdqqm.ku.c.hngzkdng.vqqn.vjcv.jgnru. qw.etgcvg.tgcfcdng.cpcn ugu.cu. qw.ecp.mggr.eqfg.kocigu.eqoogpvu.hqtowncg.cpf.rnqvu.vqigvjgtA\n",
            "--------------------\n",
            "Predicted sentence: \n",
            "tupyter motebooktupyter notebook formerly known as the Iiython notebook is a flesible tool that helps you create readable analyses as you can keep code images comments formulae and plots together.\n",
            "Decrypted sentence is : \n",
            "Jupyter NotebookJupyter notebook formerly known as the IPython notebook is a flexible tool that helps you create readable analyses as you can keep code images comments formulae and plots together.\n"
          ]
        }
      ]
    }
  ]
}