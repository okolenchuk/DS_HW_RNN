{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Обучите простую рекуррентную нейронную сеть (без GRU/LSTM, без внимания) решать задачу дешифровки шифра Цезаря:\n",
        "1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на N каждой буквы). Например если N=2, то буква A переходит в букву C. Можно поиграться с\n",
        "языком на выбор (немецкий, русский и т.д.)\n",
        "2. Создать архитектуру рекуррентной нейронной сети.\n",
        "3. Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза).\n",
        "4. Проверить качество модели.\n",
        "\n",
        "\n",
        "2 балла за правильно выполненное задание."
      ],
      "metadata": {
        "id": "hu5AdfZrYbWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import warnings\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "np.set_printoptions(threshold=1000)"
      ],
      "metadata": {
        "id": "o2HAvpCDcJPC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем файл с текстом из интернета"
      ],
      "metadata": {
        "id": "lHnxCK8gW8-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ku2kLBLUW3XF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5cb9f8-1733-493a-bd51-fe59e34be833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-18 11:30:43--  https://tululu.org/txt.php?id=51554\n",
            "Resolving tululu.org (tululu.org)... 104.21.82.5, 172.67.167.88, 2606:4700:3034::6815:5205, ...\n",
            "Connecting to tululu.org (tululu.org)|104.21.82.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 667704 (652K) [text/plain]\n",
            "Saving to: ‘txt.php?id=51554.5’\n",
            "\n",
            "\rtxt.php?id=51554.5    0%[                    ]       0  --.-KB/s               \rtxt.php?id=51554.5  100%[===================>] 652.05K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-09-18 11:30:43 (12.3 MB/s) - ‘txt.php?id=51554.5’ saved [667704/667704]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://tululu.org/txt.php?id=51554"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/txt.php?id=51554'\n",
        "string_size = 60\n",
        "batch_size = 10\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.01"
      ],
      "metadata": {
        "id": "sG4a6DuppJ2s"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс для кодирования текста по правилам шифта Цезаря с заданным шагом, и раскодировки для проверки на незнакомом корпусе текста. Также создает словарь для кодировки при чтении файла."
      ],
      "metadata": {
        "id": "IY8jM_BTYAxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cesar(object):\n",
        "    def __init__(self, step):\n",
        "        self.step = step\n",
        "        self.alphabet = ''\n",
        "        self.len_alphabet = 0\n",
        "\n",
        "    def alphabet_from_file(self, file_path):\n",
        "        with open(file_path) as file:\n",
        "            while True:\n",
        "                text = file.read(string_size)\n",
        "                if not text:\n",
        "                    break\n",
        "                for ch in text:\n",
        "                    if ch not in self.alphabet:\n",
        "                        self.alphabet += ch\n",
        "        self.alphabet = re.sub(r'[^a-zA-Z.!? ]+', r'', ''.join(sorted(self.alphabet)))\n",
        "        self.len_alphabet = len(self.alphabet)\n",
        "\n",
        "    def encode(self, text):\n",
        "        res = ''\n",
        "        for c in text:\n",
        "            if c in self.alphabet:\n",
        "                res += self.alphabet[(self.alphabet.index(c) + self.step) % len(self.alphabet)]\n",
        "        return res\n",
        "\n",
        "    def decode(self, text):\n",
        "        res = ''\n",
        "        for c in text:\n",
        "            res += self.alphabet[(self.alphabet.index(c) - self.step% len(self.alphabet))]\n",
        "        return res\n",
        "\n",
        "coder = Cesar(2)\n",
        "coder.alphabet_from_file(file_path)\n",
        "alpha = coder.alphabet\n",
        "alpha"
      ],
      "metadata": {
        "id": "U71xz6-0X_gZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1ff28ee-c549-4597-e3eb-bd76057fd4c8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' !.?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переводим части текста в массив чисел по индексу буквы в словаре и генерируем тензоры для обучения"
      ],
      "metadata": {
        "id": "yEYYF6oiITb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_index(sentence):\n",
        "    return [alpha.find(y) for y in sentence]"
      ],
      "metadata": {
        "id": "40O72RQ5G4zq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tensor(file_path, step):\n",
        "    text_array = []\n",
        "    with open(file_path) as file:\n",
        "        while True:\n",
        "            text = file.read(step)\n",
        "            if not text:\n",
        "                break\n",
        "            text_array.append(re.sub(r'[^a-zA-Z.!? ]', r' ', text))\n",
        "    del text_array[-1]\n",
        "    y_train = torch.tensor([sent_to_index(lines) for lines in text_array[:4*len(text_array) // 5]])\n",
        "    x_train = torch.tensor([sent_to_index(coder.encode(lines)) for lines in text_array[:4*len(text_array) // 5]])\n",
        "\n",
        "    y_test = torch.tensor([sent_to_index(lines) for lines in text_array[4*len(text_array) // 5:]])\n",
        "    x_test = torch.tensor([sent_to_index(coder.encode(lines)) for lines in text_array[4*len(text_array) // 5:]])\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "qKUqXFMstiQe"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = make_tensor(file_path, string_size)"
      ],
      "metadata": {
        "id": "qC_PKMetP4LZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс для датасетов для подачи в даталоадер."
      ],
      "metadata": {
        "id": "PgQtz-3dIu0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        self._len = len(x)\n",
        "        self.y = y\n",
        "        self.x = x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "uthtmZrubcxT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torch.utils.data.DataLoader(MyDataset(x_train, y_train), \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=True)\n",
        "test_ds = torch.utils.data.DataLoader(MyDataset(x_test, y_test), \n",
        "                                       batch_size=batch_size, \n",
        "                                       shuffle=True)"
      ],
      "metadata": {
        "id": "wHLltvFyRPbn"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простая RNN модель"
      ],
      "metadata": {
        "id": "8vLFKQzoI1gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = torch.nn.Embedding(60, 32)\n",
        "        self.rnn = torch.nn.RNN(32, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128, len(alpha))\n",
        "\n",
        "    def forward(self, sentence, state=None):\n",
        "        x = self.embed(sentence)\n",
        "        out, hidden = self.rnn(x)\n",
        "        return self.linear(out)"
      ],
      "metadata": {
        "id": "vVbEqG9Ntuli"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализация модели, фукции потерь и оптимизатора"
      ],
      "metadata": {
        "id": "RhBARzJVJEWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel().to(DEVICE)\n",
        "loss = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "jZCqaNPykT7Q"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc, iter_num = .0, .0, .0\n",
        "    start_epoch_time = time.time()\n",
        "    model.train()\n",
        "    for x, y in train_ds:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.view(1, -1).squeeze().to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model.forward(x).view(-1, len(alpha))\n",
        "        l = loss(out, y)\n",
        "        train_loss += l.item()\n",
        "        batch_acc = (out.argmax(dim=1) == y)\n",
        "        train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        iter_num += 1\n",
        "    print(f\"Epoch: {epoch+1}, loss: {train_loss:.4f}, acc: \"\n",
        "        f\"{train_acc / iter_num:.4f}\",\n",
        "        end=\" | \")\n",
        "    test_loss, test_acc, iter_num = .0, .0, .0\n",
        "    model.eval()\n",
        "    for x, y in test_ds:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.view(1, -1).squeeze()\n",
        "        out = model.forward(x).view(-1, len(alpha)).to(DEVICE)\n",
        "        l = loss(out, y)\n",
        "        test_loss += l.item()\n",
        "        batch_acc = (out.argmax(dim=1) == y)\n",
        "        test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
        "        iter_num += 1\n",
        "    print(\n",
        "        f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
        "        f\"{time.time() - start_epoch_time:.2f} sec.\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt7V1NoTt6-L",
        "outputId": "6d45b637-736f-4e2f-ca1e-dd02d129b52a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, loss: 1181.0266, acc: 0.7861 | test loss: 100.9240, test acc: 0.9479 | 10.12 sec.\n",
            "Epoch: 2, loss: 250.0898, acc: 0.9697 | test loss: 42.2988, test acc: 0.9771 | 10.17 sec.\n",
            "Epoch: 3, loss: 133.7215, acc: 0.9786 | test loss: 28.5908, test acc: 0.9785 | 10.04 sec.\n",
            "Epoch: 4, loss: 98.0773, acc: 0.9821 | test loss: 22.6376, test acc: 0.9826 | 10.12 sec.\n",
            "Epoch: 5, loss: 79.9862, acc: 0.9852 | test loss: 19.0181, test acc: 0.9857 | 9.92 sec.\n",
            "Epoch: 6, loss: 68.1352, acc: 0.9880 | test loss: 16.4295, test acc: 0.9892 | 9.98 sec.\n",
            "Epoch: 7, loss: 59.3662, acc: 0.9899 | test loss: 14.4260, test acc: 0.9910 | 10.12 sec.\n",
            "Epoch: 8, loss: 52.4600, acc: 0.9910 | test loss: 12.8142, test acc: 0.9924 | 10.01 sec.\n",
            "Epoch: 9, loss: 46.8313, acc: 0.9925 | test loss: 11.4864, test acc: 0.9934 | 10.02 sec.\n",
            "Epoch: 10, loss: 42.1517, acc: 0.9935 | test loss: 10.3737, test acc: 0.9939 | 10.09 sec.\n",
            "Epoch: 11, loss: 38.1818, acc: 0.9945 | test loss: 9.4285, test acc: 0.9947 | 10.14 sec.\n",
            "Epoch: 12, loss: 34.7809, acc: 0.9951 | test loss: 8.6155, test acc: 0.9955 | 10.07 sec.\n",
            "Epoch: 13, loss: 31.8350, acc: 0.9959 | test loss: 7.9108, test acc: 0.9963 | 9.99 sec.\n",
            "Epoch: 14, loss: 29.2504, acc: 0.9968 | test loss: 7.2952, test acc: 0.9972 | 10.03 sec.\n",
            "Epoch: 15, loss: 26.9861, acc: 0.9976 | test loss: 6.7546, test acc: 0.9975 | 10.10 sec.\n",
            "Epoch: 16, loss: 24.9929, acc: 0.9978 | test loss: 6.2771, test acc: 0.9977 | 10.04 sec.\n",
            "Epoch: 17, loss: 23.2244, acc: 0.9979 | test loss: 5.8540, test acc: 0.9977 | 10.12 sec.\n",
            "Epoch: 18, loss: 21.6584, acc: 0.9980 | test loss: 5.4773, test acc: 0.9978 | 9.90 sec.\n",
            "Epoch: 19, loss: 20.2521, acc: 0.9981 | test loss: 5.1407, test acc: 0.9979 | 9.94 sec.\n",
            "Epoch: 20, loss: 19.0006, acc: 0.9982 | test loss: 4.8390, test acc: 0.9979 | 10.09 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ячейка для тестирования модели на любом тексте, в sentence можно внести любой текст на английском для проверки."
      ],
      "metadata": {
        "id": "O_okU-P2J8xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"Jupyter Notebook\n",
        "Jupyter notebook, formerly known as the IPython notebook, is a flexible tool that helps you create readable analyses, \n",
        "as you can keep code, images, comments, formulae and plots together.\"\"\"\n",
        "encrypted_sentence = coder.encode(sentence)\n",
        "encrypted_sentence_idx = sent_to_index(encrypted_sentence)\n",
        "result = model(torch.tensor([encrypted_sentence_idx]).to(DEVICE)).argmax(dim=2)\n",
        "deencrypted_sentence = \"\".join([alpha[i.item()] for i in result.flatten()])\n",
        "print(f'Encrypted sentence is : \\n{encrypted_sentence}')\n",
        "print(\"-\" * 20)\n",
        "print(f'Predicted sentence: \\n{deencrypted_sentence}')\n",
        "print(f'Decrypted sentence is : \\n{coder.decode(encrypted_sentence)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uQLpQj7uHzF",
        "outputId": "931e5df5-5ab8-4159-d611-b5ec86d8799c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encrypted sentence is : \n",
            "Lwr vgt.PqvgdqqmLwr vgt.pqvgdqqm.hqtogtn .mpqyp.cu.vjg.KR vjqp.pqvgdqqm.ku.c.hngzkdng.vqqn.vjcv.jgnru. qw.etgcvg.tgcfcdng.cpcn ugu.cu. qw.ecp.mggr.eqfg.kocigu.eqoogpvu.hqtowncg.cpf.rnqvu.vqigvjgtA\n",
            "--------------------\n",
            "Predicted sentence: \n",
            "Jupyter Notebookuupyter notebook formerly known as the Iiython notebook is a flexible tool that helps you create readable analyses as you can keep code images comments formulae and plots together.\n",
            "Decrypted sentence is : \n",
            "Jupyter NotebookJupyter notebook formerly known as the IPython notebook is a flexible tool that helps you create readable analyses as you can keep code images comments formulae and plots together.\n"
          ]
        }
      ]
    }
  ]
}