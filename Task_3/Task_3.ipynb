{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YbzZhFZOfWvE"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dt3ktz8V20Q-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a685c51-ea0a-42e2-b40c-2ec8e97fec34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class LanguageVocabulary(object):\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            # Если такое уже слово есть просто добавляем 1 что добавилось одно слово\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "f2eh0h3VvKaz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    # s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-ZĄĆĘŁŃÓŚŹŻąćęłńóśźż.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "FB4bJicWvL80"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_languages(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    lines = open('/content/drive/MyDrive/RNN/pol.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "    pairs = [[normalize_string(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = LanguageVocabulary(lang2)\n",
        "        output_lang = LanguageVocabulary(lang1)\n",
        "    else:\n",
        "        input_lang = LanguageVocabulary(lang1)\n",
        "        output_lang = LanguageVocabulary(lang2)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "5n_QzLiSvNaf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = read_languages(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.add_sentence(pair[0])\n",
        "        output_lang.add_sentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "ctj7mvnYvW0E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepare_data('eng', 'pol', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7MHtch2vXPz",
        "outputId": "c44f7e76-7130-4d54-fc35-d4acf25ba667"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 46424 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "pol 29928\n",
            "eng 13324\n",
            "['tom odpowiedział na pytania policjanta.', 'tom answered the policeman s questions.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 100"
      ],
      "metadata": {
        "id": "hk2B6NZg_WAs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "wFhw0wYJvbMQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0])) # берем output по нулевому индексу (одно предложение)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "tBn6mty0vejW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "cKZn8Y3xvf0u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    loss = 0\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "GxUl-8r6viY5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / percent\n",
        "    rs = es - s\n",
        "    return '%s (- eta: %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "wyVX68Oevj5_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.05):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_iters):\n",
        "        training_pair = training_pairs[epoch - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_iters),\n",
        "                                         epoch, epoch / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "3D7V_kEBvlEZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "AnSxWnG_vmpq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "            encoder_outputs[i] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = [] # Наши деокдированные слова\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "SKom-y6Zvnzv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "kFwMn4ypvprA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "trainIters(encoder1, decoder1, 10*len(pairs), print_every=5000)"
      ],
      "metadata": {
        "id": "B4aDzKS_vqsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130304dc-121c-4dec-8d18-87dc87c177fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 13s (- eta: 112m 22s) (5000 1%) 4.8653\n",
            "1m 57s (- eta: 89m 12s) (10000 2%) 4.5193\n",
            "2m 42s (- eta: 81m 11s) (15000 3%) 4.4038\n",
            "3m 28s (- eta: 77m 15s) (20000 4%) 4.2728\n",
            "4m 15s (- eta: 74m 45s) (25000 5%) 4.2126\n",
            "5m 0s (- eta: 72m 29s) (30000 6%) 4.0897\n",
            "5m 45s (- eta: 70m 31s) (35000 7%) 4.0387\n",
            "6m 30s (- eta: 69m 2s) (40000 8%) 3.9639\n",
            "7m 15s (- eta: 67m 39s) (45000 9%) 3.9265\n",
            "8m 1s (- eta: 66m 26s) (50000 10%) 3.9009\n",
            "8m 46s (- eta: 65m 15s) (55000 11%) 3.8325\n",
            "9m 31s (- eta: 64m 9s) (60000 12%) 3.7386\n",
            "10m 16s (- eta: 63m 6s) (65000 14%) 3.7057\n",
            "11m 1s (- eta: 62m 6s) (70000 15%) 3.6701\n",
            "11m 46s (- eta: 61m 6s) (75000 16%) 3.6466\n",
            "12m 32s (- eta: 60m 11s) (80000 17%) 3.6405\n",
            "13m 17s (- eta: 59m 19s) (85000 18%) 3.5878\n",
            "14m 2s (- eta: 58m 24s) (90000 19%) 3.5752\n",
            "14m 48s (- eta: 57m 31s) (95000 20%) 3.5515\n",
            "15m 32s (- eta: 56m 37s) (100000 21%) 3.4971\n",
            "16m 17s (- eta: 55m 45s) (105000 22%) 3.4777\n",
            "17m 3s (- eta: 54m 56s) (110000 23%) 3.4836\n",
            "17m 48s (- eta: 54m 6s) (115000 24%) 3.3866\n",
            "18m 34s (- eta: 53m 16s) (120000 25%) 3.4005\n",
            "19m 20s (- eta: 52m 29s) (125000 26%) 3.3803\n",
            "20m 6s (- eta: 51m 42s) (130000 28%) 3.3627\n",
            "20m 52s (- eta: 50m 54s) (135000 29%) 3.3634\n",
            "21m 37s (- eta: 50m 4s) (140000 30%) 3.3387\n",
            "22m 23s (- eta: 49m 17s) (145000 31%) 3.3351\n",
            "23m 9s (- eta: 48m 31s) (150000 32%) 3.2886\n",
            "23m 56s (- eta: 47m 45s) (155000 33%) 3.2774\n",
            "24m 41s (- eta: 46m 57s) (160000 34%) 3.2889\n",
            "25m 26s (- eta: 46m 8s) (165000 35%) 3.2921\n",
            "26m 12s (- eta: 45m 21s) (170000 36%) 3.2208\n",
            "26m 59s (- eta: 44m 36s) (175000 37%) 3.2366\n",
            "27m 44s (- eta: 43m 48s) (180000 38%) 3.2171\n",
            "28m 29s (- eta: 43m 0s) (185000 39%) 3.2049\n",
            "29m 14s (- eta: 42m 12s) (190000 40%) 3.2103\n",
            "30m 0s (- eta: 41m 26s) (195000 42%) 3.1827\n",
            "30m 45s (- eta: 40m 38s) (200000 43%) 3.1534\n",
            "31m 30s (- eta: 39m 51s) (205000 44%) 3.1392\n",
            "32m 16s (- eta: 39m 3s) (210000 45%) 3.1848\n",
            "33m 1s (- eta: 38m 16s) (215000 46%) 3.1473\n",
            "33m 46s (- eta: 37m 29s) (220000 47%) 3.1633\n",
            "34m 31s (- eta: 36m 42s) (225000 48%) 3.1560\n",
            "35m 16s (- eta: 35m 55s) (230000 49%) 3.1461\n",
            "36m 2s (- eta: 35m 9s) (235000 50%) 3.1588\n",
            "36m 46s (- eta: 34m 21s) (240000 51%) 3.1338\n",
            "37m 32s (- eta: 33m 35s) (245000 52%) 3.1383\n",
            "38m 17s (- eta: 32m 48s) (250000 53%) 3.0843\n",
            "39m 2s (- eta: 32m 2s) (255000 54%) 3.0625\n",
            "39m 47s (- eta: 31m 15s) (260000 56%) 3.0902\n",
            "40m 31s (- eta: 30m 28s) (265000 57%) 3.0711\n",
            "41m 16s (- eta: 29m 41s) (270000 58%) 3.0454\n",
            "42m 2s (- eta: 28m 55s) (275000 59%) 3.0338\n",
            "42m 47s (- eta: 28m 9s) (280000 60%) 3.0555\n",
            "43m 32s (- eta: 27m 23s) (285000 61%) 3.0570\n",
            "44m 17s (- eta: 26m 36s) (290000 62%) 3.0737\n",
            "45m 2s (- eta: 25m 50s) (295000 63%) 3.0528\n",
            "45m 47s (- eta: 25m 3s) (300000 64%) 3.0406\n",
            "46m 32s (- eta: 24m 17s) (305000 65%) 3.0798\n",
            "47m 16s (- eta: 23m 31s) (310000 66%) 3.0541\n",
            "48m 1s (- eta: 22m 45s) (315000 67%) 3.0270\n",
            "48m 46s (- eta: 21m 59s) (320000 68%) 3.0411\n",
            "49m 31s (- eta: 21m 13s) (325000 70%) 3.0484\n",
            "50m 16s (- eta: 20m 27s) (330000 71%) 3.0324\n",
            "51m 1s (- eta: 19m 40s) (335000 72%) 3.0057\n",
            "51m 46s (- eta: 18m 55s) (340000 73%) 2.9538\n",
            "52m 31s (- eta: 18m 9s) (345000 74%) 2.9845\n",
            "53m 16s (- eta: 17m 23s) (350000 75%) 3.0501\n",
            "54m 0s (- eta: 16m 37s) (355000 76%) 3.0890\n",
            "54m 45s (- eta: 15m 51s) (360000 77%) 3.0549\n",
            "55m 30s (- eta: 15m 5s) (365000 78%) 3.0638\n",
            "56m 15s (- eta: 14m 19s) (370000 79%) 3.0809\n",
            "57m 0s (- eta: 13m 33s) (375000 80%) 3.1886\n",
            "57m 45s (- eta: 12m 48s) (380000 81%) 3.2388\n",
            "58m 30s (- eta: 12m 2s) (385000 82%) 3.2644\n",
            "59m 18s (- eta: 11m 17s) (390000 84%) 3.3310\n",
            "60m 3s (- eta: 10m 31s) (395000 85%) 3.3254\n",
            "60m 48s (- eta: 9m 46s) (400000 86%) 3.4143\n",
            "61m 34s (- eta: 9m 0s) (405000 87%) 3.3527\n",
            "62m 20s (- eta: 8m 14s) (410000 88%) 3.3329\n",
            "63m 5s (- eta: 7m 29s) (415000 89%) 3.3774\n",
            "63m 50s (- eta: 6m 43s) (420000 90%) 3.4529\n",
            "64m 35s (- eta: 5m 57s) (425000 91%) 3.5695\n",
            "65m 21s (- eta: 5m 12s) (430000 92%) 3.8080\n",
            "66m 6s (- eta: 4m 26s) (435000 93%) 3.7354\n",
            "66m 51s (- eta: 3m 41s) (440000 94%) 3.6777\n",
            "67m 36s (- eta: 2m 55s) (445000 95%) 3.6866\n",
            "68m 20s (- eta: 2m 9s) (450000 96%) 3.6943\n",
            "69m 6s (- eta: 1m 24s) (455000 98%) 3.6020\n",
            "69m 50s (- eta: 0m 38s) (460000 99%) 3.5592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def evaluateRandomly(encoder, decoder, n=1000):\n",
        "    candidate_corpus = []\n",
        "    references_corpus = []\n",
        "    for i in range(n):\n",
        "        coded, origin = random.choice(pairs)\n",
        "        references_corpus.append(origin.split(' '))\n",
        "        output_words = evaluate(encoder, decoder, coded)\n",
        "        candidate_corpus.append(output_words)\n",
        "        output_sentence = ' '.join(output_words[:-1])\n",
        "        if i%100 == 0:\n",
        "          print('>', coded)\n",
        "          print('=', origin)\n",
        "          print('<', output_sentence, '  --> ', output_sentence.replace(' <EOS>', '') == origin)\n",
        "          print('')\n",
        "        # if output_sentence.replace(' <EOS>', '') == origin:\n",
        "        #   acc +=1\n",
        "    print(f'BLEU {bleu_score(candidate_corpus, references_corpus, max_n=2, weights = [0.5, 0.5])}')"
      ],
      "metadata": {
        "id": "_j3EeZACeaTg"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPaKZTNvtUt",
        "outputId": "0b78d337-2bba-4d5a-f960-a0af3941c8a0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> zrobiłem ciasto biszkoptowe.\n",
            "= i made a sponge cake.\n",
            "< i always wanted to my   -->  False\n",
            "\n",
            "> nie przestawaj.\n",
            "= don t stop.\n",
            "< he didn   -->  False\n",
            "\n",
            "> słyszałem jak spiewała.\n",
            "= i heard her singing.\n",
            "< i heard heard how to   -->  False\n",
            "\n",
            "> skoncz kłamac.\n",
            "= quit lying.\n",
            "< he need   -->  False\n",
            "\n",
            "> tom jest przeziebiony.\n",
            "= tom has a cold.\n",
            "< tom is   -->  False\n",
            "\n",
            "> myslałem ze jasno powiedziałem ze nie chce tego robic.\n",
            "= i thought i d made it clear that i didn t want to do that.\n",
            "< i thought that didn t that that that that.   -->  False\n",
            "\n",
            "> przyjdz tez jutro!\n",
            "= come again tomorrow.\n",
            "< the also a   -->  False\n",
            "\n",
            "> nie mozesz jeszcze przejsc na emeryture.\n",
            "= you can t retire yet.\n",
            "< can can t go yet.   -->  False\n",
            "\n",
            "> nigdy nie słyszałem jak mowi po angielsku.\n",
            "= i have never heard him speak english.\n",
            "< can speak speak never   -->  False\n",
            "\n",
            "> ktora strona wygrała?\n",
            "= which side won?\n",
            "< he   -->  False\n",
            "\n",
            "BLEU 0.006234269123524427\n"
          ]
        }
      ]
    }
  ]
}